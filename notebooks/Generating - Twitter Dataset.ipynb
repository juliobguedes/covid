{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a \"Tweets\" dataset using Twint\n",
    "\n",
    "So, have you ever played **Plague, Inc**?\n",
    "* Yes!\n",
    "    * So, you probably remember those (annoying, maybe?) popups while you were playing, with news related to your disease. I'm importing that idea to our visualization page but instead of news I'll be using tweets from news portals Twitter Accounts.\n",
    "* No :(\n",
    "    * (TLDR) In `Plague, Inc`, news of your ficticious world pop up during the game. I consider it a cool idea and want to do it using real tweets.\n",
    "    * Then I'll have to explain the idea to you. When you are playing `Plague, Inc`, you have in your power a bacteria, a virus, a fungus, or something that can cause an infectious disease. As long as your playing, you are able to evolve your disease by giving it new/stronger ways to infect, new/stronger synthoms, and new/stronger resistance to medicine. The days are passing by before you can get new points to acquire or evolve your disease's \"skills\", and while the time passes, news from that world start popping up in your screen. An example would be \"Tokyo 2020 Olympics postponed to 2021 due to *name of your disease*\". What we want to do is to create real popups in our visualization, something like \"Tokyo Olympics postponed to 2021 due to coronavirus\" and a link to that tweet from `The Guardian`, with that headline; in the tweet, you would probably see a link to that [news story](https://www.theguardian.com/sport/2020/mar/24/tokyo-olympics-to-be-postponed-to-2021-due-to-coronavirus-pandemic). Cool, huh?\n",
    "\n",
    "From now on, we will be mining those tweets using [Twint](https://github.com/twint-project/twint), an open-source crawler that can scrape every tweet from a given date until the time of the query is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dependencies and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, json\n",
    "import twint\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using `news_asyncio` because `twint` is one of many libraries that does not work that nicely in a jupyter notebook, and can cause problems with asynchronous calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "datapath = '../data/twitter_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets2df(tweets, country):\n",
    "    def tweet2json(tweet):\n",
    "        return {\n",
    "            'id': tweet.id,\n",
    "            'datestamp': tweet.datestamp,\n",
    "            'timestamp': tweet.timestamp,\n",
    "            'username': tweet.username,\n",
    "            'tweet': tweet.tweet,\n",
    "            'replies_count': tweet.replies_count,\n",
    "            'retweets_count': tweet.retweets_count,\n",
    "            'likes_count': tweet.likes_count,\n",
    "            'url': tweet.link,\n",
    "            'country': country\n",
    "        }\n",
    "    \n",
    "    jsons = [tweet2json(tweet) for tweet in tweets]\n",
    "    df = pd.DataFrame(jsons)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_twint(username, since='2020-01-22'):\n",
    "    twint.output.tweets_list = []\n",
    "    tw = twint.Config()\n",
    "    tw.Username = newspaper\n",
    "    tw.Since = '2020-01-22'\n",
    "    tw.Store_object = True\n",
    "    tw.Stats = True\n",
    "    tw.Hide_output = True\n",
    "    return tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create(country, newspaper):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(f'Creating {newspaper} of {country}')\n",
    "    dfname = f'{country}_{newspaper}.tsv'\n",
    "    tw = config_twint(newspaper)\n",
    "\n",
    "    twint.run.Search(tw)\n",
    "\n",
    "    df = tweets2df(twint.output.tweets_list, country)\n",
    "    if (dfname == 'China_chinaorgcn.tsv'):\n",
    "        df.to_json(f'{datapath}/{dfname}')\n",
    "    else:\n",
    "        df.to_csv(f'{datapath}/{dfname}', sep='\\t', index=False)\n",
    "\n",
    "def update(country, newspaper):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    print(f'Updating {newspaper} of {country}')\n",
    "    dfname = f'{country}_{newspaper}.tsv'\n",
    "    dfname2 = f'{country}_{newspaper}_updated.tsv'\n",
    "    if (dfname == 'China_chinaorgcn.tsv'):\n",
    "        past = pd.read_json(f'{datapath}/{dfname}')\n",
    "    else:\n",
    "        past = pd.read_csv(f'{datapath}/{dfname}', sep='\\t', engine='python')\n",
    "    past.sort_values(['datestamp'], inplace=True, ascending=False)\n",
    "    most_recent = past['datestamp'][0] + \" \" + past['timestamp'][0]\n",
    "    print(f'Querying from {most_recent}. The current dataset has {len(past)} samples.')\n",
    "    \n",
    "    tw = config_twint(newspaper, most_recent)\n",
    "    twint.run.Search(tw)\n",
    "\n",
    "    df = tweets2df(twint.output.tweets_list, country)\n",
    "    print(f'The updated dataset has {len(df)} samples')\n",
    "    if (dfname == 'China_chinaorgcn.tsv'):\n",
    "        df.to_json(f'{datapath}/{dfname2}')\n",
    "    else:\n",
    "        df.to_csv(f'{datapath}/{dfname2}', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {\n",
    "    'US': ['cnn', 'nytimes', 'huffpost', 'FoxNews'],\n",
    "    'Brazil': ['g1', 'folha', 'Estadao', 'JornalOGlobo', 'JornaldoBrasil'],\n",
    "    'Italy': ['repubblica', 'Corriere', 'Libero_official', 'virgilio_it'],\n",
    "    'UK': ['BBCNews', 'guardian', 'MailOnline', 'Telegraph'],\n",
    "    'China': ['ChinaDaily', 'PDChina', 'shanghaidaily', 'chinaorgcn']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['id', 'datestamp, timestamp', 'username', 'tweet', 'replies_count', 'retweets_count', 'likes_count', 'url']\n",
    "formatted = '\"' + \"\\t\".join(['{' + field + '}' for field in fields]) + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating cnn of US\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 10560 samples.\n",
      "The updated dataset has 11619 samples\n",
      "Updating nytimes of US\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 16732 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "The updated dataset has 3660 samples\n",
      "Updating huffpost of US\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 20849 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "The updated dataset has 0 samples\n",
      "Updating FoxNews of US\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 20919 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "The updated dataset has 0 samples\n",
      "Updating g1 of Brazil\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 22348 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:noDataExpecting value: line 1 column 1 (char 0)\n",
      "CRITICAL:root:twint.run:Twint:Feed:Tweets_known_error:Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting value: line 1 column 1 (char 0) [x] run.Feed\n",
      "[!] if get this error but you know for sure that more tweets exist, please open an issue and we will investigate it!\n",
      "The updated dataset has 0 samples\n",
      "Updating folha of Brazil\n",
      "Querying from 2020-03-29 03:01:06. The current dataset has 34135 samples.\n"
     ]
    }
   ],
   "source": [
    "for country in countries.keys():\n",
    "    newspapers = countries[country]\n",
    "    for newspaper in newspapers:\n",
    "        dfname = f'{country}_{newspaper}.tsv'\n",
    "        if dfname in os.listdir(datapath):\n",
    "            update(country, newspaper)\n",
    "        else:\n",
    "            create(country, newspaper)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets2df(twint.output.tweets_list, country)\n",
    "df.to_json(f'{datapath}/{dfname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:covid]",
   "language": "python",
   "name": "conda-env-covid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
