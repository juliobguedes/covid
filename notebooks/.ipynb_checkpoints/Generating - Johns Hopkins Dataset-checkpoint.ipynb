{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our own dataset from Johns Hopkins COVID Dataset\n",
    "\n",
    "PLEASE NOTE THAT THIS NOTEBOOK CONTAINS ERRORS THAT I MADE. PLEASE IGNORE IT FOR NOW, I WILL FIX IT LATER!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, json\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "\n",
    "We are interested in analyzing the `.csv` files compiled and provided by the Johns Hopkins University, that can be [accessed here](https://data.humdata.org/dataset/novel-coronavirus-2019-ncov-cases). There are 6 different files to analyze: `time_series_2019-ncov-Confirmed.csv`, `time_series_2019-ncov-Recovered.csv`, `time_series_2019-ncov-Deaths.csv`, `time_series-ncov-Confirmed.csv`, `time_series-ncov-Recovered.csv` and `time_series-ncov-Deaths.csv`. As their name says, there are two different styles of file, and we also need to understand what changes between them.\n",
    "\n",
    "PS: Later on, the Johns Hopkins University introduces a third pattern of data which was considered in this analysis and replaces the second pattern.\n",
    "\n",
    "The files are downloaded into the `data/` folder, and they will be loaded using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data'\n",
    "ts_2019_deaths = pd.read_csv(f'{datapath}/time_series_2019-ncov-Deaths.csv')\n",
    "ts_2019_recov = pd.read_csv(f'{datapath}/time_series_2019-ncov-Recovered.csv')\n",
    "ts_2019_conf = pd.read_csv(f'{datapath}/time_series_2019-ncov-Confirmed.csv')\n",
    "\n",
    "ts_deaths = pd.read_csv(f'{datapath}/time_series-ncov-Deaths.csv')\n",
    "ts_recov = pd.read_csv(f'{datapath}/time_series-ncov-Recovered.csv')\n",
    "ts_conf = pd.read_csv(f'{datapath}/time_series-ncov-Confirmed.csv')\n",
    "\n",
    "ts_n_deaths = pd.read_csv(f'{datapath}/time_series_covid19_deaths_global_narrow.csv')\n",
    "ts_n_recov = pd.read_csv(f'{datapath}/time_series_covid19_recovered_global_narrow.csv')\n",
    "ts_n_conf = pd.read_csv(f'{datapath}/time_series_covid19_confirmed_global_narrow.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look into the the Confirmed cases file of the pattern that contains `2019` in the name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/14/20</th>\n",
       "      <th>3/15/20</th>\n",
       "      <th>3/16/20</th>\n",
       "      <th>3/17/20</th>\n",
       "      <th>3/18/20</th>\n",
       "      <th>3/19/20</th>\n",
       "      <th>3/20/20</th>\n",
       "      <th>3/21/20</th>\n",
       "      <th>3/22/20</th>\n",
       "      <th>3/23/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>114</td>\n",
       "      <td>147</td>\n",
       "      <td>177</td>\n",
       "      <td>212</td>\n",
       "      <td>272</td>\n",
       "      <td>322</td>\n",
       "      <td>411</td>\n",
       "      <td>599</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>36.0000</td>\n",
       "      <td>138.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>773</td>\n",
       "      <td>839</td>\n",
       "      <td>825</td>\n",
       "      <td>878</td>\n",
       "      <td>889</td>\n",
       "      <td>924</td>\n",
       "      <td>963</td>\n",
       "      <td>1007</td>\n",
       "      <td>1086</td>\n",
       "      <td>1086.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.2833</td>\n",
       "      <td>103.8333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>226</td>\n",
       "      <td>243</td>\n",
       "      <td>266</td>\n",
       "      <td>313</td>\n",
       "      <td>345</td>\n",
       "      <td>385</td>\n",
       "      <td>432</td>\n",
       "      <td>455</td>\n",
       "      <td>455.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Nepal</td>\n",
       "      <td>28.1667</td>\n",
       "      <td>84.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Malaysia</td>\n",
       "      <td>2.5000</td>\n",
       "      <td>112.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>238</td>\n",
       "      <td>428</td>\n",
       "      <td>566</td>\n",
       "      <td>673</td>\n",
       "      <td>790</td>\n",
       "      <td>900</td>\n",
       "      <td>1030</td>\n",
       "      <td>1183</td>\n",
       "      <td>1306</td>\n",
       "      <td>1306.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat      Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN       Thailand  15.0000  101.0000        2        3        5   \n",
       "1            NaN          Japan  36.0000  138.0000        2        1        2   \n",
       "2            NaN      Singapore   1.2833  103.8333        0        1        3   \n",
       "3            NaN          Nepal  28.1667   84.2500        0        0        0   \n",
       "4            NaN       Malaysia   2.5000  112.5000        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  3/14/20  3/15/20  3/16/20  3/17/20  \\\n",
       "0        7        8        8  ...       82      114      147      177   \n",
       "1        2        4        4  ...      773      839      825      878   \n",
       "2        3        4        5  ...      212      226      243      266   \n",
       "3        1        1        1  ...        1        1        1        1   \n",
       "4        3        4        4  ...      238      428      566      673   \n",
       "\n",
       "   3/18/20  3/19/20  3/20/20  3/21/20  3/22/20  3/23/20  \n",
       "0      212      272      322      411      599    599.0  \n",
       "1      889      924      963     1007     1086   1086.0  \n",
       "2      313      345      385      432      455    455.0  \n",
       "3        1        1        1        1        2      2.0  \n",
       "4      790      900     1030     1183     1306   1306.0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_2019_conf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can realize that some columns refer to the identification of the entity, with information such as the name of the country and its latitude and longitude. The rest of the columns refer to every day since January 22, 2020. By generalization, we will assume that the other two files of this pattern have the same column style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now look what changes between the patterns by looking into the second:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#adm1+name</td>\n",
       "      <td>#country+name</td>\n",
       "      <td>#geo+lat</td>\n",
       "      <td>#geo+lon</td>\n",
       "      <td>#date</td>\n",
       "      <td>#affected+infected+value+num</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat      Long        Date  \\\n",
       "0     #adm1+name  #country+name  #geo+lat  #geo+lon       #date   \n",
       "1            NaN    Afghanistan      33.0      65.0  2020-03-23   \n",
       "2            NaN    Afghanistan      33.0      65.0  2020-03-22   \n",
       "3            NaN    Afghanistan      33.0      65.0  2020-03-21   \n",
       "4            NaN    Afghanistan      33.0      65.0  2020-03-20   \n",
       "\n",
       "                          Value  \n",
       "0  #affected+infected+value+num  \n",
       "1                            40  \n",
       "2                            40  \n",
       "3                            24  \n",
       "4                            24  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_conf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the first row, which seems to be a header, we now have the same information structured differently: each row represents a day in a Country or a Province, and the `Value` column represents the number of Confirmed cases in that day. Considering that we want to extract the number of Confirmed, Recovered and Death cases, this last structure configuration is more interesting.\n",
    "\n",
    "Lets look into a Country to confirm that the days have the same range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-21</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-14</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-12</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Province/State Country/Region   Lat  Long        Date Value\n",
       "1             NaN    Afghanistan  33.0  65.0  2020-03-23    40\n",
       "2             NaN    Afghanistan  33.0  65.0  2020-03-22    40\n",
       "3             NaN    Afghanistan  33.0  65.0  2020-03-21    24\n",
       "4             NaN    Afghanistan  33.0  65.0  2020-03-20    24\n",
       "5             NaN    Afghanistan  33.0  65.0  2020-03-19    22\n",
       "6             NaN    Afghanistan  33.0  65.0  2020-03-18    22\n",
       "7             NaN    Afghanistan  33.0  65.0  2020-03-17    22\n",
       "8             NaN    Afghanistan  33.0  65.0  2020-03-16    21\n",
       "9             NaN    Afghanistan  33.0  65.0  2020-03-15    16\n",
       "10            NaN    Afghanistan  33.0  65.0  2020-03-14    11\n",
       "11            NaN    Afghanistan  33.0  65.0  2020-03-13     7\n",
       "12            NaN    Afghanistan  33.0  65.0  2020-03-12     7\n",
       "13            NaN    Afghanistan  33.0  65.0  2020-03-11     7\n",
       "14            NaN    Afghanistan  33.0  65.0  2020-03-10     5\n",
       "15            NaN    Afghanistan  33.0  65.0  2020-03-09     4\n",
       "16            NaN    Afghanistan  33.0  65.0  2020-03-08     4\n",
       "17            NaN    Afghanistan  33.0  65.0  2020-03-07     1\n",
       "18            NaN    Afghanistan  33.0  65.0  2020-03-06     1\n",
       "19            NaN    Afghanistan  33.0  65.0  2020-03-05     1\n",
       "20            NaN    Afghanistan  33.0  65.0  2020-03-04     1\n",
       "21            NaN    Afghanistan  33.0  65.0  2020-03-03     1\n",
       "22            NaN    Afghanistan  33.0  65.0  2020-03-02     1\n",
       "23            NaN    Afghanistan  33.0  65.0  2020-03-01     1\n",
       "24            NaN    Afghanistan  33.0  65.0  2020-02-29     1\n",
       "25            NaN    Afghanistan  33.0  65.0  2020-02-28     1\n",
       "26            NaN    Afghanistan  33.0  65.0  2020-02-27     1\n",
       "27            NaN    Afghanistan  33.0  65.0  2020-02-26     1\n",
       "28            NaN    Afghanistan  33.0  65.0  2020-02-25     1\n",
       "29            NaN    Afghanistan  33.0  65.0  2020-02-24     1\n",
       "30            NaN    Afghanistan  33.0  65.0  2020-02-23     0\n",
       "31            NaN    Afghanistan  33.0  65.0  2020-02-22     0\n",
       "32            NaN    Afghanistan  33.0  65.0  2020-02-21     0\n",
       "33            NaN    Afghanistan  33.0  65.0  2020-02-20     0\n",
       "34            NaN    Afghanistan  33.0  65.0  2020-02-19     0\n",
       "35            NaN    Afghanistan  33.0  65.0  2020-02-18     0\n",
       "36            NaN    Afghanistan  33.0  65.0  2020-02-17     0\n",
       "37            NaN    Afghanistan  33.0  65.0  2020-02-16     0\n",
       "38            NaN    Afghanistan  33.0  65.0  2020-02-15     0\n",
       "39            NaN    Afghanistan  33.0  65.0  2020-02-14     0\n",
       "40            NaN    Afghanistan  33.0  65.0  2020-02-13     0\n",
       "41            NaN    Afghanistan  33.0  65.0  2020-02-12     0\n",
       "42            NaN    Afghanistan  33.0  65.0  2020-02-11     0\n",
       "43            NaN    Afghanistan  33.0  65.0  2020-02-10     0\n",
       "44            NaN    Afghanistan  33.0  65.0  2020-02-09     0\n",
       "45            NaN    Afghanistan  33.0  65.0  2020-02-08     0\n",
       "46            NaN    Afghanistan  33.0  65.0  2020-02-07     0\n",
       "47            NaN    Afghanistan  33.0  65.0  2020-02-06     0\n",
       "48            NaN    Afghanistan  33.0  65.0  2020-02-05     0\n",
       "49            NaN    Afghanistan  33.0  65.0  2020-02-04     0\n",
       "50            NaN    Afghanistan  33.0  65.0  2020-02-03     0\n",
       "51            NaN    Afghanistan  33.0  65.0  2020-02-02     0\n",
       "52            NaN    Afghanistan  33.0  65.0  2020-02-01     0\n",
       "53            NaN    Afghanistan  33.0  65.0  2020-01-31     0\n",
       "54            NaN    Afghanistan  33.0  65.0  2020-01-30     0\n",
       "55            NaN    Afghanistan  33.0  65.0  2020-01-29     0\n",
       "56            NaN    Afghanistan  33.0  65.0  2020-01-28     0\n",
       "57            NaN    Afghanistan  33.0  65.0  2020-01-27     0\n",
       "58            NaN    Afghanistan  33.0  65.0  2020-01-26     0\n",
       "59            NaN    Afghanistan  33.0  65.0  2020-01-25     0\n",
       "60            NaN    Afghanistan  33.0  65.0  2020-01-24     0\n",
       "61            NaN    Afghanistan  33.0  65.0  2020-01-23     0\n",
       "62            NaN    Afghanistan  33.0  65.0  2020-01-22     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_conf[ts_conf['Country/Region'] == 'Afghanistan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the days also range from January 22, 2020 to March 23, 2020, they are perfect to use.\n",
    "\n",
    "### UPDATE\n",
    "\n",
    "A few days after we first did this, the Johns Hopkins University stoped releasing the second pattern of datasets and started releasing a third pattern. Lets take a peek into the ts_n pattern to check if they have the same features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Date</th>\n",
       "      <th>Value</th>\n",
       "      <th>ISO 3166-1 Alpha 3-Codes</th>\n",
       "      <th>Region Code</th>\n",
       "      <th>Sub-region Code</th>\n",
       "      <th>Intermediate Region Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#adm1+name</td>\n",
       "      <td>#country+name</td>\n",
       "      <td>#geo+lat</td>\n",
       "      <td>#geo+lon</td>\n",
       "      <td>#date</td>\n",
       "      <td>#affected+infected+value+num</td>\n",
       "      <td>#country+code</td>\n",
       "      <td>#region+main+code</td>\n",
       "      <td>#region+sub+code</td>\n",
       "      <td>#region+intermediate+code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>299</td>\n",
       "      <td>AFG</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>281</td>\n",
       "      <td>AFG</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>273</td>\n",
       "      <td>AFG</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2020-04-01</td>\n",
       "      <td>237</td>\n",
       "      <td>AFG</td>\n",
       "      <td>142</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region       Lat      Long        Date  \\\n",
       "0     #adm1+name  #country+name  #geo+lat  #geo+lon       #date   \n",
       "1            NaN    Afghanistan      33.0      65.0  2020-04-04   \n",
       "2            NaN    Afghanistan      33.0      65.0  2020-04-03   \n",
       "3            NaN    Afghanistan      33.0      65.0  2020-04-02   \n",
       "4            NaN    Afghanistan      33.0      65.0  2020-04-01   \n",
       "\n",
       "                          Value ISO 3166-1 Alpha 3-Codes        Region Code  \\\n",
       "0  #affected+infected+value+num            #country+code  #region+main+code   \n",
       "1                           299                      AFG                142   \n",
       "2                           281                      AFG                142   \n",
       "3                           273                      AFG                142   \n",
       "4                           237                      AFG                142   \n",
       "\n",
       "    Sub-region Code   Intermediate Region Code  \n",
       "0  #region+sub+code  #region+intermediate+code  \n",
       "1                34                        NaN  \n",
       "2                34                        NaN  \n",
       "3                34                        NaN  \n",
       "4                34                        NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_n_conf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now confirmed that they do have the same features, and we must start using the ts_n dataframes to generate the json data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our own dataset\n",
    "\n",
    "Now that we have chosen the pattern, lets apply some changes in the data and join all the csvs into a single dataframe.\n",
    "\n",
    "PS: The starting code for creating our own dataset had bugs, which caused inconsistencies in the data used in the visualization. The starting code has now been replaced with a version of the code that works. You can check both versions of the code in previous commits in the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '#affected+infected+value+num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5b27a3aca7c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mts_n_deaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_n_deaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int64'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mts_n_recov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_n_recov\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int64'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mts_n_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts_n_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'Value'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int64'\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5682\u001b[0m                     results.append(\n\u001b[0;32m-> 5683\u001b[0;31m                         \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5684\u001b[0m                     )\n\u001b[1;32m   5685\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/covid/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '#affected+infected+value+num'"
     ]
    }
   ],
   "source": [
    "ts_n_deaths = ts_n_deaths.astype({ 'Value': 'int64' })\n",
    "ts_n_recov = ts_n_recov.astype({ 'Value': 'int64' })\n",
    "ts_n_conf = ts_n_conf.astype({ 'Value': 'int64' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to structure the data in an useful way to manipulate it when creating our visualization. For that, it is interesting to remove the province identification and keep the identification by Country and Date. Therefore, we are grouping the data by Country and Date, and the value in the Confirmed, Recovered and Death will be the sum of the values in each province.\n",
    "\n",
    "For example, if in February 1st we had the rows:\n",
    "```\n",
    "USA - Arizona - 21 Confirmed - 0 Recovered - 0 Deaths,\n",
    "USA - California - 97 Confirmed - 1 Recovered - 3 Deaths,\n",
    "USA - Idaho - 2 Confirmed - 0 Recovered - 0 Deaths,\n",
    "USA - Texas - 210 Confirmed - 5 Recovered - 2 Deaths\n",
    "```\n",
    "\n",
    "The result of the groupby would be:\n",
    "```\n",
    "USA - 330 Confirmed - 6 Recovered - 5 Deaths\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_deaths = ts_n_deaths.groupby(['Country/Region', 'Date']).agg({ 'Value': 'sum' })\n",
    "grouped_recov = ts_n_recov.groupby(['Country/Region', 'Date']).agg({ 'Value': 'sum' })\n",
    "grouped_conf = ts_n_conf.groupby(['Country/Region', 'Date']).agg({ 'Value': 'sum' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_deaths.columns = ['Deaths']\n",
    "grouped_recov.columns = ['Recovered']\n",
    "grouped_conf.columns = ['Confirmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = grouped_deaths.merge(grouped_recov, left_index=True, right_index=True)\n",
    "grouped = grouped.merge(grouped_conf, left_index=True, right_index=True)\n",
    "grouped.reset_index(drop=False, inplace=True)\n",
    "grouped.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.to_csv(f'{datapath}/covid_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Jsons\n",
    "\n",
    "Now we will generate our json using the data we have previously seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = grouped['Country/Region'].unique()\n",
    "covid_jsons = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country in countries:\n",
    "    ts_segment = grouped[grouped['Country/Region'] == country].copy().reset_index()\n",
    "    \n",
    "    covid_json = {\n",
    "        'country': country,\n",
    "        'latitude': ts_n_deaths.loc[1]['Lat'],\n",
    "        'longitude': ts_n_deaths.loc[1]['Long'],\n",
    "        'dates': ts_segment['Date'].tolist(),\n",
    "        'confirmed': ts_segment['Confirmed'].tolist(),\n",
    "        'deaths': ts_segment['Deaths'].tolist(),\n",
    "        'recovered': ts_segment['Recovered'].tolist()\n",
    "    }\n",
    "    covid_jsons.append(covid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{datapath}/covid_data.json', 'w') as json_path:\n",
    "    json.dump(covid_jsons, json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick problem when creating the map\n",
    "\n",
    "When we first created the map in the `Generating Map` notebook, some of the countries such as the US have not appeared in the map. The probable cause of this problem is a wrong mapping between the keys in the json we just generated and the name that exists in the `.shp` file. Lets see if it is the case:\n",
    "\n",
    "PS: The data was updated later, including the ISO code for each country. Since our mapping was already done, lets keep it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shp_countries():\n",
    "    fname = 'plane_countries.ndjson'\n",
    "    with open(f'{datapath}/{fname}', 'r') as ndjson:\n",
    "        lines = ndjson.readlines()\n",
    "        \n",
    "    countries = []\n",
    "    for line in lines:\n",
    "        jsline = json.loads(line)\n",
    "        ci = jsline['properties']['COUNTRY']\n",
    "        countries.append(ci)\n",
    "    c_set = set(countries)\n",
    "    return c_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_countries = load_shp_countries()\n",
    "country_set = set(countries.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff1 = list(country_set - shp_countries.intersection(country_set))\n",
    "diff1.sort()\n",
    "\n",
    "diff2 = list(shp_countries - shp_countries.intersection(country_set))\n",
    "diff2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"; \".join(diff1))\n",
    "print()\n",
    "print(\"; \".join(diff2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our assumption was correct, we now need to map (using human knowledge and the internet to prevent mismatches) the country names in the country set to the names in the shp set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'Congo (Brazzaville)': 'Congo',\n",
    "    'Congo (Kinshasa)': 'Democratic Republic of the Congo',\n",
    "    'Cote d\\'Ivoire': 'Ivory Coast',\n",
    "    'Czechia': 'Czech Republic',\n",
    "    'French Guiana': 'French Guiana (France)',\n",
    "    'Greenland': 'Greenland (Denmark)',\n",
    "    'Guadeloupe': 'Guadeloupe (France)',\n",
    "    'Guam': 'Guam (US)',\n",
    "    'Guernsey': 'Guernsey (UK)',\n",
    "    'Jersey': 'Jersey (UK)',\n",
    "    'Korea, South': 'South Korea',\n",
    "    'Martinique': 'Martinique (France)',\n",
    "    'Mayotte': 'Mayotte (France)',\n",
    "    'North Macedonia': 'Macedonia',\n",
    "    'Puerto Rico': 'Puerto Rico (US)',\n",
    "    'Reunion': 'Reunion (France)',\n",
    "    'Saint Lucia': 'St. Lucia',\n",
    "    'Saint Vincent and the Grenadines': 'St. Vincent and the Grenadines',\n",
    "    'Taiwan*': 'Taiwan',\n",
    "    'The Bahamas': 'Bahamas',\n",
    "    'The Gambia': 'Gambia',\n",
    "    'US': 'United States'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_jsons = []\n",
    "for country in countries:\n",
    "    ts_segment = grouped[grouped['Country/Region'] == country].copy().reset_index()\n",
    "    \n",
    "    covid_json = {\n",
    "        'country': mapping[country] if country in mapping else country,\n",
    "        'latitude': ts_n_deaths.loc[1]['Lat'],\n",
    "        'longitude': ts_n_deaths.loc[1]['Long'],\n",
    "        'dates': ts_segment['Date'].tolist(),\n",
    "        'confirmed': ts_segment['Confirmed'].tolist(),\n",
    "        'deaths': ts_segment['Deaths'].tolist(),\n",
    "        'recovered': ts_segment['Recovered'].tolist()\n",
    "    }\n",
    "    covid_jsons.append(covid_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{datapath}/covid_updated.json', 'w') as json_path:\n",
    "    json.dump(covid_jsons, json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data for the chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_json = {}\n",
    "daily_data = {}\n",
    "\n",
    "for country in countries:\n",
    "    segment = grouped[grouped['Country/Region'] == country].reset_index()\n",
    "\n",
    "    daily = []\n",
    "    for index, row in segment.iterrows():\n",
    "        daily.append({\n",
    "            'date': row['Date'],\n",
    "            'confirmed': row['Confirmed'],\n",
    "            'deaths': row['Deaths'],\n",
    "            'recovered': row['Deaths']\n",
    "        })\n",
    "        \n",
    "        if row['Date'] in daily_data:\n",
    "            daily_data[row['Date']]['confirmed'] += row['Confirmed']\n",
    "            daily_data[row['Date']]['deaths'] += row['Deaths']\n",
    "            daily_data[row['Date']]['recovered'] += row['Recovered']\n",
    "        else:\n",
    "            daily_data[row['Date']] = {\n",
    "                'confirmed': row['Confirmed'],\n",
    "                'deaths': row['Deaths'],\n",
    "                'recovered': row['Recovered']\n",
    "            }\n",
    "    \n",
    "    country_name = mapping[country] if country in mapping else country\n",
    "    chart_json[country_name] = {\n",
    "        'country': country_name,\n",
    "        'data': daily\n",
    "    }\n",
    "\n",
    "\n",
    "world_data = []\n",
    "for key in daily_data.keys():\n",
    "    daily_data[key]['date'] = key\n",
    "    world_data.append(daily_data[key])\n",
    "world_obj = {\n",
    "    'country': 'World',\n",
    "    'data': world_data\n",
    "}\n",
    "chart_json['World'] = world_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{datapath}/covid_chart.json', 'w') as covid_chart:\n",
    "    json.dump(chart_json, covid_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ../data/covid_chart.json ../docs/data/covid_chart.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil = grouped[grouped['Country/Region'] == 'Brazil'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.plot.bar(x='Date', y='Confirmed', title='Casos Confirmados no Brasil', figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.plot.bar(x='Date', y='Deaths', title='Ã“bitos no Brasil', figsize=(16, 12), color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil.plot.bar(x='Date', y='Recovered', title='Casos de RecuperaÃ§Ã£o no Brasil', figsize=(16, 12), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chile = grouped[grouped['Country/Region'] == 'Chile'].reset_index()\n",
    "# chile = chile.reindex(index=chile.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chile.plot.bar(x='Date', y='Confirmed', title='Casos Confirmados no Brasil', figsize=(16, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chile.plot.bar(x='Date', y='Deaths', title='Casos Confirmados no Brasil', figsize=(16, 12), color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chile.plot.bar(x='Date', y='Recovered', title='Casos Confirmados no Brasil', figsize=(16, 12), color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:covid]",
   "language": "python",
   "name": "conda-env-covid-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
